import cv2
import os
import tempfile
import numpy as np
from mmaction.apis import inference_recognizer, init_recognizer
from mmengine.config import Config

# üßæ –ü—É—Ç—å –∫ –∫–æ–Ω—Ñ–∏–≥—É –∏ —á–µ–∫–ø–æ–π–Ω—Ç—É
config_file = '/home/ppds/PycharmProjects/gluh/tsm_mobilenetv2_bukva.py'
checkpoint_file = '/home/ppds/PycharmProjects/mmaction2/work_dirs/tsm_bukva/best_acc_top1_epoch_1.pth'
device = 'cpu'

# üî§ –ê–ª—Ñ–∞–≤–∏—Ç
label_map = {i: chr(1040 + i) for i in range(32)}  # –ê-–Ø
label_map[32] = '–Å'
label_map[33] = ' '

# üé• –ü—É—Ç—å –∫ –≤–∏–¥–µ–æ
video_path = 'test_data/b.mp4'

# üì• –í—ã–≥—Ä—É–∂–∞–µ–º –∫–∞–¥—Ä—ã –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É
tmp_dir = tempfile.TemporaryDirectory()
frame_paths = []

cap = cv2.VideoCapture(video_path)
assert cap.isOpened(), f'–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ: {video_path}'

frame_id = 0
while True:
    ret, frame = cap.read()
    if not ret:
        break
    frame_path = os.path.join(tmp_dir.name, f'{frame_id:06d}.jpg')
    cv2.imwrite(frame_path, frame)
    frame_paths.append(frame_path)
    frame_id += 1

cap.release()

# ‚öôÔ∏è –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
model = init_recognizer(config_file, checkpoint_file, device=device)

# üß† –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
result = inference_recognizer(model, frame_paths)

# üéØ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
pred_scores = result.pred_score.cpu().numpy()

if len(pred_scores) == 1:
    pred_label = 0
    pred_score = float(pred_scores[0])
    print("‚ö†Ô∏è –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ —Ç–æ–ª—å–∫–æ –Ω–∞ 1 –∫–ª–∞—Å—Å. –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏–Ω–¥–µ–∫—Å 0.")
else:
    pred_label = np.argmax(pred_scores)
    pred_score = float(pred_scores[pred_label])

pred_letter = label_map.get(pred_label, f"[{pred_label}]")
print(f'üìç –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: {pred_letter} (score: {pred_score:.2f})')

# üßπ –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–∞–¥—Ä—ã
tmp_dir.cleanup()
